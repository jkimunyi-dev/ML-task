{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6993401a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, epochs=50, patience=10):\n",
    "    \"\"\"Train the model with early stopping\"\"\"\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=calculate_class_weights(train_loader, device))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize variables for early stopping\n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    no_improve_epochs = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        val_acc, val_f1, _ = test_model(model, val_loader, device, verbose=False)\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f'Epoch {epoch+1}/{epochs} | Time: {epoch_time:.2f}s')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Acc: {val_acc:.2f}% | Val F1: {val_f1:.4f}')\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(val_f1)\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            no_improve_epochs = 0\n",
    "            # Save the best model\n",
    "            torch.save(best_model_state, 'dsan_model_rafdb_best.pth')\n",
    "            print(f\"Saved new best model with F1: {best_f1:.4f}\")\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            print(f\"No improvement for {no_improve_epochs} epochs\")\n",
    "            \n",
    "        if no_improve_epochs >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Load the best model\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"Loaded best model with F1: {best_f1:.4f}\")\n",
    "    \n",
    "    # Save the final model\n",
    "    torch.save(model.state_dict(), 'dsan_model_rafdb.pth')\n",
    "    print(\"Saved final model\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def calculate_class_weights(train_loader, device):\n",
    "    \"\"\"Calculate class weights for handling class imbalance\"\"\"\n",
    "    class_counts = torch.zeros(7, dtype=torch.float)\n",
    "    \n",
    "    for _, labels in train_loader:\n",
    "        for label in labels:\n",
    "            class_counts[label] += 1\n",
    "    \n",
    "    # Calculate weights (inverse of frequency)\n",
    "    weights = 1.0 / class_counts\n",
    "    # Normalize weights\n",
    "    weights = weights / weights.sum() * len(weights)\n",
    "    \n",
    "    return weights.to(device)\n",
    "\n",
    "def test_model(model, test_loader, device, verbose=True):\n",
    "    \"\"\"Test the model on the test dataset\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0] * 7\n",
    "    class_total = [0] * 7\n",
    "    emotion_labels = ['Surprise', 'Fear', 'Disgust', 'Happiness', 'Sadness', 'Anger', 'Neutral']\n",
    "    \n",
    "    confusion_matrix = torch.zeros(7, 7)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "                \n",
    "                # Update confusion matrix\n",
    "                confusion_matrix[label][pred] += 1\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # Calculate F1 score for each class\n",
    "    f1_scores = []\n",
    "    for i in range(7):\n",
    "        # Calculate precision and recall\n",
    "        tp = confusion_matrix[i][i].item()\n",
    "        fp = confusion_matrix[:, i].sum().item() - tp\n",
    "        fn = confusion_matrix[i, :].sum().item() - tp\n",
    "        \n",
    "        precision = tp / max(tp + fp, 1)\n",
    "        recall = tp / max(tp + fn, 1)\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = 2 * precision * recall / max(precision + recall, 1e-6)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # Calculate mean F1 score\n",
    "    mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "        # Print per-class accuracy\n",
    "        print('\\nPer-class accuracy:')\n",
    "        for i in range(7):\n",
    "            class_acc = 100 * class_correct[i] / max(class_total[i], 1)\n",
    "            print(f'{emotion_labels[i]}: {class_acc:.2f}% ({class_correct[i]}/{class_total[i]})')\n",
    "        \n",
    "        # Print F1 scores\n",
    "        print('\\nPer-class F1 scores:')\n",
    "        for i in range(7):\n",
    "            print(f'{emotion_labels[i]}: {f1_scores[i]:.4f}')\n",
    "        \n",
    "        print(f'\\nMean F1 Score: {mean_f1:.4f}')\n",
    "    \n",
    "    return accuracy, mean_f1, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414fe99",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46469bc1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    \"\"\"Get data transformations for training and testing\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7203794",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to train and test the model on RAF-DB dataset\"\"\"\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Data transformations\n",
    "    train_transform, test_transform = get_transforms()\n",
    "    \n",
    "    # Path settings for the directory structure\n",
    "    raf_db_root = \"./data/rafdb/DATASET\"  # Path to the dataset root\n",
    "    \n",
    "    # Create train and validation datasets\n",
    "    try:\n",
    "        # Load train dataset\n",
    "        train_dataset = RAFDBFolderDataset(\n",
    "            root_dir=raf_db_root,\n",
    "            split='train',\n",
    "            transform=train_transform\n",
    "        )\n",
    "        \n",
    "        # Create validation split (20% of training data)\n",
    "        train_size = int(0.8 * len(train_dataset))\n",
    "        val_size = len(train_dataset) - train_size\n",
    "        \n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            train_dataset, \n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "        \n",
    "        # Apply correct transforms to validation split\n",
    "        val_dataset.dataset = copy.deepcopy(train_dataset.dataset)\n",
    "        val_dataset.dataset.transform = test_transform\n",
    "        \n",
    "        # Create test dataset\n",
    "        test_dataset = RAFDBFolderDataset(\n",
    "            root_dir=raf_db_root,\n",
    "            split='test',\n",
    "            transform=test_transform\n",
    "        )\n",
    "        \n",
    "        # Handle class imbalance with WeightedRandomSampler\n",
    "        # Count samples per class in training set\n",
    "        class_counts = [0] * 7\n",
    "        for _, label in train_dataset:\n",
    "            class_counts[label] += 1\n",
    "        \n",
    "        # Calculate weights for each sample in training set\n",
    "        weights = torch.zeros(len(train_dataset))\n",
    "        for idx, (_, label) in enumerate(train_dataset):\n",
    "            # Weight = 1 / class_count\n",
    "            weights[idx] = 1.0 / class_counts[label]\n",
    "        \n",
    "        # Create WeightedRandomSampler\n",
    "        sampler = torch.utils.data.WeightedRandomSampler(\n",
    "            weights=weights,\n",
    "            num_samples=len(train_dataset),\n",
    "            replacement=True\n",
    "        )\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=32,\n",
    "            sampler=sampler,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "        print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "        print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "        \n",
    "        # Create model\n",
    "        model = DSAN(num_classes=7, pretrained=True)\n",
    "        model = model.to(device)\n",
    "        print(f\"Model created with {count_parameters(model):,} trainable parameters\")\n",
    "        \n",
    "        # Check if we want to load a pretrained model\n",
    "        model_path = \"./dsan_model_rafdb.pth\"\n",
    "        train_model_flag = True\n",
    "        \n",
    "        if os.path.exists(model_path) and not train_model_flag:\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            print(f\"Loaded pretrained model from {model_path}\")\n",
    "        else:\n",
    "            print(\"Training new model...\")\n",
    "            # Train the model\n",
    "            model = train_model(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                device=device,\n",
    "                epochs=50,\n",
    "                patience=10\n",
    "            )\n",
    "        \n",
    "        # Test the model\n",
    "        print(\"\\nEvaluating model on test set:\")\n",
    "        accuracy, mean_f1, conf_matrix = test_model(model, test_loader, device)\n",
    "        \n",
    "        # Visualize confusion matrix\n",
    "        cm_fig = visualize_confusion_matrix(conf_matrix)\n",
    "        cm_fig.savefig(\"confusion_matrix_rafdb.png\")\n",
    "        print(\"Saved confusion matrix visualization to confusion_matrix_rafdb.png\")\n",
    "        \n",
    "        # Visualize sample predictions\n",
    "        sample_fig = visualize_sample_predictions(model, test_loader, device)\n",
    "        sample_fig.savefig(\"sample_predictions_rafdb.png\")\n",
    "        print(\"Saved sample predictions visualization to sample_predictions_rafdb.png\")\n",
    "        \n",
    "        # Visualize attention maps\n",
    "        visualize_attention_maps(model, test_loader, device)\n",
    "        \n",
    "        # Save evaluation results\n",
    "        with open(\"evaluation_results_rafdb.txt\", \"w\") as f:\n",
    "            f.write(f\"Test Accuracy: {accuracy:.2f}%\\n\")\n",
    "            f.write(f\"Mean F1 Score: {mean_f1:.4f}\\n\")\n",
    "        \n",
    "        print(\"Evaluation completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during dataset loading or evaluation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e37e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class RAFDBFolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    RAF-DB dataset loader for folder-based structure\n",
    "    \n",
    "    The RAF-DB dataset contains 7 emotion categories mapped to folder numbers:\n",
    "    1: Surprise, 2: Fear, 3: Disgust, 4: Happiness, 5: Sadness, 6: Anger, 7: Neutral\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, split='test', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Root directory of the RAF-DB dataset.\n",
    "            split (string): 'train' or 'test' split.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        # Check if directory exists\n",
    "        if not os.path.exists(self.root_dir):\n",
    "            raise RuntimeError(f\"Dataset directory not found: {self.root_dir}\")\n",
    "        \n",
    "        # Class mapping based on RAF-DB folder numbering\n",
    "        self.class_to_idx = {\n",
    "            '1': 0,  # Surprise\n",
    "            '2': 1,  # Fear\n",
    "            '3': 2,  # Disgust\n",
    "            '4': 3,  # Happiness\n",
    "            '5': 4,  # Sadness\n",
    "            '6': 5,  # Anger\n",
    "            '7': 6,  # Neutral\n",
    "        }\n",
    "        \n",
    "        # Load all samples from the directory structure\n",
    "        class_samples = {cls: 0 for cls in self.class_to_idx.values()}\n",
    "        \n",
    "        for class_folder in sorted(os.listdir(self.root_dir)):\n",
    "            class_path = os.path.join(self.root_dir, class_folder)\n",
    "            if os.path.isdir(class_path) and class_folder in self.class_to_idx:\n",
    "                class_idx = self.class_to_idx[class_folder]\n",
    "                img_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                class_samples[class_idx] = len(img_files)\n",
    "                print(f\"Class {class_folder} ({self.get_class_name(class_idx)}): {len(img_files)} images\")\n",
    "                for img_file in img_files:\n",
    "                    self.samples.append((os.path.join(class_path, img_file), class_idx))\n",
    "        \n",
    "        print(f\"Total samples in {split} set: {len(self.samples)}\")\n",
    "        \n",
    "        # Calculate class weights for handling imbalance\n",
    "        total_samples = sum(class_samples.values())\n",
    "        self.class_weights = {cls: total_samples / (len(class_samples) * count) \n",
    "                             if count > 0 else 0 \n",
    "                             for cls, count in class_samples.items()}\n",
    "    \n",
    "    def get_class_weights(self):\n",
    "        \"\"\"Get class weights for handling imbalance\"\"\"\n",
    "        return self.class_weights\n",
    "    \n",
    "    def get_class_name(self, class_idx):\n",
    "        \"\"\"Get emotion name from class index\"\"\"\n",
    "        emotion_labels = ['Surprise', 'Fear', 'Disgust', 'Happiness', 'Sadness', 'Anger', 'Neutral']\n",
    "        return emotion_labels[class_idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a placeholder image and the same label\n",
    "            placeholder = torch.zeros(3, 224, 224) if self.transform else Image.new('RGB', (224, 224))\n",
    "            return placeholder, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c85ff0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Updated model class with additional improvements\n",
    "class DSANPlus(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced Dual Stream Attention Network for Facial Emotion Recognition\n",
    "    \n",
    "    Improvements:\n",
    "    - Added Dropout for regularization\n",
    "    - Enhanced attention modules\n",
    "    - Added residual connections\n",
    "    - Added batch normalization\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=7, pretrained=True, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use ResNet18 as backbone for feature extraction\n",
    "        resnet = models.resnet18(pretrained=pretrained)\n",
    "\n",
    "        # GFE-AN Stream (Global Feature Extraction with Attention Network)\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.gfe_attention1 = SparseAttention(64)\n",
    "        self.bn_gfe1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.gfe_attention2 = SparseAttention(128)\n",
    "        self.bn_gfe2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # MFF-AN Stream (Multi-scale Feature Fusion with Attention Network)\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.mff_attention1 = LocalFeatureAttention(256)\n",
    "        self.bn_mff1 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.mff_attention2 = LocalFeatureAttention(512)\n",
    "        self.bn_mff2 = nn.BatchNorm2d(512)\n",
    "\n",
    "        # Global pooling and classification\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Two-stage classifier\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.bn_fc = nn.BatchNorm1d(256)\n",
    "        self.relu_fc = nn.ReLU(inplace=True)\n",
    "        self.dropout_fc = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "        # Store attention maps for visualization\n",
    "        self.attention_maps = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reset attention maps storage\n",
    "        self.attention_maps = []\n",
    "\n",
    "        # GFE-AN Stream\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # Layer 1 with residual connection\n",
    "        identity1 = x\n",
    "        x = self.layer1(x)\n",
    "        # Store pre-attention feature map for visualization\n",
    "        pre_attn1 = x.detach().clone()\n",
    "        x_attn = self.gfe_attention1(x)\n",
    "        x = x_attn * x + x  # Residual connection\n",
    "        x = self.bn_gfe1(x)\n",
    "        # Store attention effect for visualization\n",
    "        self.attention_maps.append((pre_attn1, x.detach().clone()))\n",
    "\n",
    "        # Layer 2 with residual connection\n",
    "        identity2 = x\n",
    "        x = self.layer2(x)\n",
    "        pre_attn2 = x.detach().clone()\n",
    "        x_attn = self.gfe_attention2(x)\n",
    "        x = x_attn * x + x  # Residual connection\n",
    "        x = self.bn_gfe2(x)\n",
    "        self.attention_maps.append((pre_attn2, x.detach().clone()))\n",
    "\n",
    "        # MFF-AN Stream\n",
    "        identity3 = x\n",
    "        x = self.layer3(x)\n",
    "        pre_attn3 = x.detach().clone()\n",
    "        x_attn = self.mff_attention1(x)\n",
    "        x = x + x_attn  # Residual connection\n",
    "        x = self.bn_mff1(x)\n",
    "        self.attention_maps.append((pre_attn3, x.detach().clone()))\n",
    "\n",
    "        identity4 = x\n",
    "        x = self.layer4(x)\n",
    "        pre_attn4 = x.detach().clone()\n",
    "        x_attn = self.mff_attention2(x)\n",
    "        x = x + x_attn  # Residual connection\n",
    "        x = self.bn_mff2(x)\n",
    "        self.attention_maps.append((pre_attn4, x.detach().clone()))\n",
    "\n",
    "        # Classification\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Two-stage classification\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn_fc(x)\n",
    "        x = self.relu_fc(x)\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def visualize_attention(self, input_img):\n",
    "        \"\"\"\n",
    "        Generate attention visualizations for a given input image\n",
    "\n",
    "        Args:\n",
    "            input_img: Input tensor of shape [1, 3, H, W]\n",
    "\n",
    "        Returns:\n",
    "            List of attention visualization figures\n",
    "        \"\"\"\n",
    "        # Ensure model is in eval mode\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Forward pass to populate attention maps\n",
    "            _ = self.forward(input_img)\n",
    "\n",
    "            visualizations = []\n",
    "\n",
    "            for i, (pre_attn, post_attn) in enumerate(self.attention_maps):\n",
    "                # Convert tensors to numpy for visualization\n",
    "                pre_feature = pre_attn[0].cpu().numpy()  # Take first image in batch\n",
    "                post_feature = post_attn[0].cpu().numpy()\n",
    "\n",
    "                # Average across channels to get attention heatmap\n",
    "                pre_feature_map = np.mean(pre_feature, axis=0)\n",
    "                post_feature_map = np.mean(post_feature, axis=0)\n",
    "\n",
    "                # Create difference map to highlight attention effect\n",
    "                diff_map = post_feature_map - pre_feature_map\n",
    "\n",
    "                # Create figure\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "                # Plot pre-attention feature map\n",
    "                im1 = axes[0].imshow(pre_feature_map, cmap='viridis')\n",
    "                axes[0].set_title(f'Layer {i+1}: Pre-Attention')\n",
    "                axes[0].axis('off')\n",
    "                plt.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "                # Plot post-attention feature map\n",
    "                im2 = axes[1].imshow(post_feature_map, cmap='viridis')\n",
    "                axes[1].set_title(f'Layer {i+1}: Post-Attention')\n",
    "                axes[1].axis('off')\n",
    "                plt.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "                # Plot difference map\n",
    "                im3 = axes[2].imshow(diff_map, cmap='RdBu_r')\n",
    "                axes[2].set_title(f'Layer {i+1}: Attention Effect')\n",
    "                axes[2].axis('off')\n",
    "                plt.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                visualizations.append(fig)\n",
    "\n",
    "            return visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab05a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472bccf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import missing modules\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to get data transformations\n",
    "def get_transforms():\n",
    "    \"\"\"Get data transformations for training and testing\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, test_transform\n",
    "\n",
    "# Function to calculate class weights\n",
    "def calculate_class_weights(train_loader, device):\n",
    "    \"\"\"Calculate class weights for handling class imbalance\"\"\"\n",
    "    class_counts = torch.zeros(7, dtype=torch.float)\n",
    "    \n",
    "    for _, labels in train_loader:\n",
    "        for label in labels:\n",
    "            class_counts[label] += 1\n",
    "    \n",
    "    # Calculate weights (inverse of frequency)\n",
    "    weights = 1.0 / class_counts\n",
    "    # Normalize weights\n",
    "    weights = weights / weights.sum() * len(weights)\n",
    "    \n",
    "    return weights.to(device)\n",
    "\n",
    "# Modified test function to allow silent operation when needed\n",
    "def test_model(model, test_loader, device, verbose=True):\n",
    "    \"\"\"Test the model on the test dataset\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0] * 7\n",
    "    class_total = [0] * 7\n",
    "    emotion_labels = ['Surprise', 'Fear', 'Disgust', 'Happiness', 'Sadness', 'Anger', 'Neutral']\n",
    "    \n",
    "    confusion_matrix = torch.zeros(7, 7)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "                \n",
    "                # Update confusion matrix\n",
    "                confusion_matrix[label][pred] += 1\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # Calculate F1 score for each class\n",
    "    f1_scores = []\n",
    "    for i in range(7):\n",
    "        # Calculate precision and recall\n",
    "        tp = confusion_matrix[i][i].item()\n",
    "        fp = confusion_matrix[:, i].sum().item() - tp\n",
    "        fn = confusion_matrix[i, :].sum().item() - tp\n",
    "        \n",
    "        precision = tp / max(tp + fp, 1)\n",
    "        recall = tp / max(tp + fn, 1)\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = 2 * precision * recall / max(precision + recall, 1e-6)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # Calculate mean F1 score\n",
    "    mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "        \n",
    "        # Print per-class accuracy\n",
    "        print('\\nPer-class accuracy:')\n",
    "        for i in range(7):\n",
    "            class_acc = 100 * class_correct[i] / max(class_total[i], 1)\n",
    "            print(f'{emotion_labels[i]}: {class_acc:.2f}% ({class_correct[i]}/{class_total[i]})')\n",
    "        \n",
    "        # Print F1 scores\n",
    "        print('\\nPer-class F1 scores:')\n",
    "        for i in range(7):\n",
    "            print(f'{emotion_labels[i]}: {f1_scores[i]:.4f}')\n",
    "        \n",
    "        print(f'\\nMean F1 Score: {mean_f1:.4f}')\n",
    "    \n",
    "    return accuracy, mean_f1, confusion_matrix\n",
    "\n",
    "# Training function with early stopping\n",
    "def train_model(model, train_loader, val_loader, device, epochs=50, patience=10):\n",
    "    \"\"\"Train the model with early stopping\"\"\"\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=calculate_class_weights(train_loader, device))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize variables for early stopping\n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    no_improve_epochs = 0\n",
    "    \n",
    "    # Save training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': [],\n",
    "        'val_f1': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        val_acc, val_f1, _ = test_model(model, val_loader, device, verbose=False)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f'Epoch {epoch+1}/{epochs} | Time: {epoch_time:.2f}s')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Acc: {val_acc:.2f}% | Val F1: {val_f1:.4f}')\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(val_f1)\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            no_improve_epochs = 0\n",
    "            # Save the best model\n",
    "            torch.save(best_model_state, 'dsan_model_rafdb_best.pth')\n",
    "            print(f\"Saved new best model with F1: {best_f1:.4f}\")\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            print(f\"No improvement for {no_improve_epochs} epochs\")\n",
    "            \n",
    "        if no_improve_epochs >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Load the best model\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"Loaded best model with F1: {best_f1:.4f}\")\n",
    "    \n",
    "    # Save the final model\n",
    "    torch.save(model.state_dict(), 'dsan_model_rafdb.pth')\n",
    "    print(\"Saved final model\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Run the training and evaluation\n",
    "def run_experiment():\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Data transformations\n",
    "    train_transform, test_transform = get_transforms()\n",
    "    \n",
    "    # Path settings for the directory structure\n",
    "    raf_db_root = \"./data/rafdb/DATASET\"  # Path to the dataset root\n",
    "    \n",
    "    try:\n",
    "        # Load train dataset\n",
    "        print(\"Loading training dataset...\")\n",
    "        train_dataset = RAFDBFolderDataset(\n",
    "            root_dir=raf_db_root,\n",
    "            split='train',\n",
    "            transform=train_transform\n",
    "        )\n",
    "        \n",
    "        # Create validation split (20% of training data)\n",
    "        train_size = int(0.8 * len(train_dataset))\n",
    "        val_size = len(train_dataset) - train_size\n",
    "        \n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            train_dataset, \n",
    "            [train_size, val_size],\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "        \n",
    "        # Apply correct transforms to validation split\n",
    "        val_dataset = copy.deepcopy(train_dataset)\n",
    "        val_dataset.dataset.transform = test_transform\n",
    "        \n",
    "        # Create test dataset\n",
    "        print(\"Loading test dataset...\")\n",
    "        test_dataset = RAFDBFolderDataset(\n",
    "            root_dir=raf_db_root,\n",
    "            split='test',\n",
    "            transform=test_transform\n",
    "        )\n",
    "        \n",
    "        # Handle class imbalance with WeightedRandomSampler\n",
    "        # Count samples per class in training set\n",
    "        class_counts = [0] * 7\n",
    "        for idx in range(len(train_dataset)):\n",
    "            _, label = train_dataset[idx]\n",
    "            class_counts[label] += 1\n",
    "        \n",
    "        # Calculate weights for each sample in training set\n",
    "        weights = torch.zeros(len(train_dataset))\n",
    "        for idx in range(len(train_dataset)):\n",
    "            _, label = train_dataset[idx]\n",
    "            # Weight = 1 / class_count\n",
    "            weights[idx] = 1.0 / class_counts[label] if class_counts[label] > 0 else 0\n",
    "        \n",
    "        # Create WeightedRandomSampler\n",
    "        sampler = torch.utils.data.WeightedRandomSampler(\n",
    "            weights=weights,\n",
    "            num_samples=len(train_dataset),\n",
    "            replacement=True\n",
    "        )\n",
    "        \n",
    "        # Create dataloaders\n",
    "        print(\"Creating data loaders...\")\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=32,\n",
    "            sampler=sampler,\n",
    "            num_workers=2,  # Reduced from 4 to avoid warnings\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "        print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "        print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "        \n",
    "        # Create model - Use enhanced model for better performance\n",
    "        print(\"Creating model...\")\n",
    "        model = DSANPlus(num_classes=7, pretrained=True, dropout_rate=0.5)\n",
    "        model = model.to(device)\n",
    "        print(f\"Model created with {count_parameters(model):,} trainable parameters\")\n",
    "        \n",
    "        # Define whether to train or just evaluate\n",
    "        train_model_flag = True\n",
    "        model_path = \"./dsan_model_rafdb.pth\"\n",
    "        \n",
    "        if os.path.exists(model_path) and not train_model_flag:\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            print(f\"Loaded pretrained model from {model_path}\")\n",
    "            \n",
    "            # Test on validation set to check performance\n",
    "            print(\"\\nEvaluating model on validation set:\")\n",
    "            val_acc, val_f1, _ = test_model(model, val_loader, device)\n",
    "        else:\n",
    "            print(\"\\nTraining new model...\")\n",
    "            # Train the model\n",
    "            model, history = train_model(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                device=device,\n",
    "                epochs=30,  # Reduced for notebook environment\n",
    "                patience=7   # Reduced for notebook environment\n",
    "            )\n",
    "        \n",
    "        # Test the model\n",
    "        print(\"\\nEvaluating model on test set:\")\n",
    "        accuracy, mean_f1, conf_matrix = test_model(model, test_loader, device)\n",
    "        \n",
    "        # Visualize confusion matrix\n",
    "        print(\"\\nGenerating confusion matrix...\")\n",
    "        cm_fig = visualize_confusion_matrix(conf_matrix)\n",
    "        cm_fig.savefig(\"confusion_matrix_rafdb.png\")\n",
    "        print(\"Saved confusion matrix visualization to confusion_matrix_rafdb.png\")\n",
    "        \n",
    "        # Visualize sample predictions\n",
    "        print(\"\\nGenerating sample predictions...\")\n",
    "        sample_fig = visualize_sample_predictions(model, test_loader, device)\n",
    "        sample_fig.savefig(\"sample_predictions_rafdb.png\")\n",
    "        print(\"Saved sample predictions visualization to sample_predictions_rafdb.png\")\n",
    "        \n",
    "        # Visualize attention maps\n",
    "        print(\"\\nGenerating attention maps...\")\n",
    "        visualize_attention_maps(model, test_loader, device, num_samples=2)  # Reduced to 2 samples\n",
    "        \n",
    "        # Save evaluation results\n",
    "        with open(\"evaluation_results_rafdb.txt\", \"w\") as f:\n",
    "            f.write(f\"Test Accuracy: {accuracy:.2f}%\\n\")\n",
    "            f.write(f\"Mean F1 Score: {mean_f1:.4f}\\n\")\n",
    "        \n",
    "        print(\"\\nEvaluation completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during experiment: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Run the experiment\n",
    "if __name__ == \"__main__\":\n",
    "    run_experiment()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
