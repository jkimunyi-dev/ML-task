{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e570d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add these imports if you're creating a new file\n",
    "# If adding to existing file, these should already be imported\n",
    "# from model import DSAN\n",
    "# from dataset import RAFDBFolderDataset\n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler,\n",
    "                device, num_epochs=25, save_path='./dsan_model_rafdb.pth',\n",
    "                log_interval=10):\n",
    "    \"\"\"\n",
    "    Train the DSAN model\n",
    "\n",
    "    Args:\n",
    "        model: Model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        test_loader: DataLoader for testing data\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        scheduler: Learning rate scheduler\n",
    "        device: Device to train on (cuda/cpu)\n",
    "        num_epochs: Number of epochs to train for\n",
    "        save_path: Path to save best model weights\n",
    "        log_interval: How often to log training progress within epoch\n",
    "\n",
    "    Returns:\n",
    "        Trained model and training history\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    best_acc = 0.0\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': [],\n",
    "        'time_per_epoch': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Use tqdm for progress bar\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for batch_idx, (inputs, labels) in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            batch_loss = loss.item() * inputs.size(0)\n",
    "            batch_corrects = torch.sum(preds == labels.data).item()\n",
    "\n",
    "            running_loss += batch_loss\n",
    "            running_corrects += batch_corrects\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            # Update progress bar\n",
    "            if batch_idx % log_interval == 0:\n",
    "                batch_acc = batch_corrects / inputs.size(0)\n",
    "                pbar.set_description(f'Train Loss: {loss.item():.4f} Acc: {batch_acc:.4f}')\n",
    "\n",
    "        # Calculate epoch stats\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = running_corrects / total_samples\n",
    "\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        val_total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Statistics\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                batch_loss = loss.item() * inputs.size(0)\n",
    "                batch_corrects = torch.sum(preds == labels.data).item()\n",
    "\n",
    "                val_running_loss += batch_loss\n",
    "                val_running_corrects += batch_corrects\n",
    "                val_total_samples += inputs.size(0)\n",
    "\n",
    "        # Calculate validation stats\n",
    "        val_epoch_loss = val_running_loss / val_total_samples\n",
    "        val_epoch_acc = val_running_corrects / val_total_samples\n",
    "\n",
    "        history['test_loss'].append(val_epoch_loss)\n",
    "        history['test_acc'].append(val_epoch_acc)\n",
    "\n",
    "        # Time per epoch\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        history['time_per_epoch'].append(epoch_time)\n",
    "\n",
    "        print(f'Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}')\n",
    "        print(f'Epoch Time: {epoch_time:.2f}s')\n",
    "\n",
    "        # Step the scheduler\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Save best model\n",
    "        if val_epoch_acc > best_acc:\n",
    "            best_acc = val_epoch_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved new best model with accuracy {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Training complete in {total_time // 60:.0f}m {total_time % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    ax1.plot(history['train_acc'], label='Train Accuracy')\n",
    "    ax1.plot(history['test_acc'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    ax2.plot(history['train_loss'], label='Train Loss')\n",
    "    ax2.plot(history['test_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    return fig\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to train the model on RAF-DB dataset\"\"\"\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Data transformations with augmentation for training\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Path settings\n",
    "    raf_db_root = \"./data/rafdb/DATASET\"  # Path to the dataset root\n",
    "\n",
    "    try:\n",
    "        # Create datasets\n",
    "        train_dataset = RAFDBFolderDataset(\n",
    "            root_dir=raf_db_root,\n",
    "            split='train',\n",
    "            transform=train_transform\n",
    "        )\n",
    "\n",
    "        test_dataset = RAFDBFolderDataset(\n",
    "            root_dir=raf_db_root,\n",
    "            split='test',\n",
    "            transform=test_transform\n",
    "        )\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "        print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "        # Create model\n",
    "        model = DSAN(num_classes=7, pretrained=True)\n",
    "        model = model.to(device)\n",
    "        print(f\"Model created with {count_parameters(model):,} trainable parameters\")\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "        # Learning rate scheduler\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "        # Train model\n",
    "        model, history = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            num_epochs=30,  # Adjust as needed\n",
    "            save_path='./dsan_model_rafdb.pth'\n",
    "        )\n",
    "\n",
    "        # Plot training history\n",
    "        plot_training_history(history)\n",
    "\n",
    "        # Evaluate model on test set after training\n",
    "        accuracy, mean_f1, conf_matrix = test_model(model, test_loader, device)\n",
    "\n",
    "        # Save evaluation results\n",
    "        with open(\"final_evaluation_results.txt\", \"w\") as f:\n",
    "            f.write(f\"Test Accuracy: {accuracy:.2f}%\\n\")\n",
    "            f.write(f\"Mean F1 Score: {mean_f1:.4f}\\n\")\n",
    "            f.write(f\"Average time per epoch: {np.mean(history['time_per_epoch']):.2f}s\\n\")\n",
    "\n",
    "        print(\"Training and evaluation completed!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
